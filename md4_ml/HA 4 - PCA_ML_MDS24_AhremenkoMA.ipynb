{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1gL2DEfNRGu"
   },
   "source": [
    "# Machine Learning\n",
    "\n",
    "## HSE, 2024-25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fdTH3pxXFLxw"
   },
   "source": [
    "### Home Assignment #4. PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sk5URBvkFLxx"
   },
   "source": [
    "Assignment completed by:\n",
    "\n",
    "    Ахременко Михаил"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqVyveO4FLxx"
   },
   "source": [
    "### General Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2A0wmBWwFLxx"
   },
   "source": [
    "__Publication date:__ 08.05.2024\n",
    "\n",
    "__Deadline:__ 04:00 20.05.2024"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qK8Ari9eFLxz"
   },
   "source": [
    "### Grading and penalties\n",
    "\n",
    "The number of points for each problem in this homework assignment is listed next to the problem condition.\n",
    "\n",
    "The homework grade is calculated using the following formula:\n",
    "\n",
    "$$\n",
    "s \\times 10/53 ,\n",
    "$$\n",
    "\n",
    "where $s$ is the number of points you have scored in total for all tasks.\n",
    "\n",
    "For submitting an assignment after the deadline, a penalty of 1 **secondary** point per day is applied to the final grade for the assignment, but the delay cannot exceed one week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nEGThfK6FLx0"
   },
   "source": [
    "__Attention!__ Homework assignments must be completed independently. \"Similar\" solutions are considered plagiarism, and all involved students (including those from whom the work was copied) will receive no more than 0 points for the assignment.\n",
    "\n",
    "Additionally, please remember that all solutions are run through a special new anti-plagiarism system for Jupyter notebooks, which detects cross-similarities between different notebooks, as well as solutions generated by neural networks. Such work will also be strictly considered as plagiarism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNja-u8vFLx0"
   },
   "source": [
    "### Submission format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_H-cf8uaFLx0"
   },
   "source": [
    "You upload your solution using the link provided in the telegram channel. You need to upload a file with the extension .ipynb (Python notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEVawss2FLxy"
   },
   "source": [
    "### About the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NXNpYAFdFLxz"
   },
   "source": [
    "In this assignment, we will practice working with linear algebra and, specifically, with the PCA algorithm. The goal of the assignment is to try to compress the soundtrack of a Beethoven melody using this dimensionality reduction algorithm, which we have discussed in detail in seminars and lectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "695Wv5Sl3qLx"
   },
   "source": [
    "First, let's import all the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bxhawxri-zK7"
   },
   "source": [
    "import pandas as pd\n",
    "from pandas.core.interchange.dataframe_protocol import DataFrame\n",
    "# Needed to read and write audio files\n",
    "from scipy.io import wavfile\n",
    "\n",
    "# This is to play audio files directly in Notebook\n",
    "from IPython.display import Audio\n",
    "\n",
    "# And this is the standard set of data analysis libraries required for this assignment\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vbW6iTq35vCU"
   },
   "source": [
    "Let's download the data:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qUn_Fmbp8mHF",
    "outputId": "1b4a9364-ae9f-4e48-b507-512053404670"
   },
   "source": "# ! wget https://www.dropbox.com/s/p5147nr8mzemxnr/Beethoven_Violin_Sonata_Op_96_first_movement_bars_1-22.wav",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TjpPcxuU52kK"
   },
   "source": [
    "Let's read the audio track using wavfile:\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CCbvIMhM-fjc"
   },
   "source": [
    "samplerate, data = wavfile.read('Beethoven_Violin_Sonata_Op_96_first_movement_bars_1-22.wav')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aj-kEh2G_CE6"
   },
   "source": [
    "In the cell above we see a certain `samplerate`. This variable stores the samplerate by default; the standard value for audio is 44100 Hz.\n",
    "\n",
    "For those who are not very familiar with sound encoding and recording methods (aka those who didn't pass the 'EGE' in computer science at school :) ), - samplerate shows how many consecutive elements of the array with the signal encode a sound of 1 second duration.\n",
    "\n",
    "You can learn more about sound encoding [here](https://ru.wikipedia.org/wiki/Кодирование_звуковой_информации)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewii49Kw8G0z"
   },
   "source": [
    "So, let's see what the sampling rate of our audio track is."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YRTtnJQF-95F",
    "outputId": "9657cac9-0d69-4ee5-fc83-75276d923251"
   },
   "source": "samplerate",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2X8RSEr98gOr"
   },
   "source": [
    "If you divide the length of the signal array by `samplerate`, you will get the duration of the audio track in seconds. At least, you should get this result!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mBt7kZgH-97Q",
    "outputId": "723cec9d-59ae-4b04-af64-fd5afff760f8"
   },
   "source": [
    "len(data) / samplerate"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qVLsvdIz8wS6"
   },
   "source": [
    "Forty-five seconds. Does that sound about right? Compare it to the length of the track by running it on your computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZzN7K-hz9aGC"
   },
   "source": [
    "Note also that the sound is stereo, as the signal is encoded with two channels (for the left and right speaker)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-rSZCrJTAF-W",
    "outputId": "4186e5f3-4286-4c0f-ce2b-e177ae39e2ae"
   },
   "source": "data.shape",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cPWoFhF9ssj"
   },
   "source": [
    "Draw the signals in both channels:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "id": "mVJaqGY5APCo",
    "outputId": "e8982168-d5d6-450c-d7bd-cde7523f9c25"
   },
   "source": [
    "# Channel 1\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(data[:, 0])\n",
    "plt.show()\n",
    "\n",
    "# Channel 2\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(data[:, 1])\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QrLOeXHV9zUc"
   },
   "source": [
    "Here it is - the legendary “cardiogram” sound we are all familiar with! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J2XcZW7k-EH9"
   },
   "source": [
    "So now let's average the channels and get a mono sound, which will be much easier to work with.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c_IvCJzCAW8b",
    "outputId": "d648527b-73b1-4e79-dec4-0298a392fbbf"
   },
   "source": [
    "mono_sound = np.mean(data, axis=1)\n",
    "mono_sound.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sp6Bj5u_-q3T"
   },
   "source": [
    "And now we're finally ready to hear what we have to compress! :)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "kX1NS2aaAgkE",
    "outputId": "19c57f43-f8be-4828-dd24-3118a57fd27a"
   },
   "source": "Audio(mono_sound, rate=samplerate)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9tPjXciOAB-S"
   },
   "source": [
    "Pretty, isn't it? :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VE9nggm7AAxy"
   },
   "source": [
    "For convenience, we will also trim the signal array so that it can be easily divided into equal parts. These parts will form the dataset that you need to compress using the methods you know.\n",
    "\n",
    "In fact, the method is very similar to the one we used to compress the picture at the seminar by splitting it into rectangular sub-pictures - only here the task is even simpler :)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ntt7wfSnA05E"
   },
   "source": [
    "mono_sound_to_cut = mono_sound[:1990000]\n",
    "# Audio(mono_sound_to_cut, rate=samplerate)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mV8YQSVBRLm"
   },
   "source": [
    "Let's check that our sound is now just a vector of numbers:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G6ysNa1zJ2tV",
    "outputId": "c244336d-58e0-4963-b81b-891d7381cd81"
   },
   "source": [
    "mono_sound_to_cut.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MTUYUPcCBcg7"
   },
   "source": [
    "Great, everything is absolutely ready!\n",
    "\n",
    "Well, that's the end of our mission; now it's your turn! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ge67s_evBOZ4"
   },
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJo-et5wJut4"
   },
   "source": [
    "\n",
    "#### 1.1. (2 points)\n",
    "Write a function that will split the signal into equal parts of length 1000 and create a dataset represented as a two-dimensional array (a matrix of objects-features), where each part of the signal of length 1000 is in a separate row."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RhWHPNaiJgGN"
   },
   "source": [
    "def split_arr(arr: np.array, chunk_size: int = 1000, col_to_split: int = 0) -> np.array:\n",
    "    if arr.ndim > 1:\n",
    "        arr = arr[:, col_to_split]  # 0 - left column, 1 - the right one\n",
    "\n",
    "    arr_len = len(arr)\n",
    "\n",
    "    size_extend = 0\n",
    "    if arr_len % chunk_size != 0:\n",
    "        zero_to_add = chunk_size - arr_len % chunk_size\n",
    "        arr = np.pad(\n",
    "            array=arr,\n",
    "            pad_width=(0, zero_to_add),\n",
    "            mode='constant',\n",
    "        )  # expand the array with zeros if it is not divisible by chunk_size\n",
    "        size_extend = 1\n",
    "\n",
    "    chunk_cnt = arr_len // chunk_size + size_extend\n",
    "    arr = arr.reshape((chunk_cnt, chunk_size))\n",
    "\n",
    "    return arr\n",
    "\n",
    "\n",
    "CHUNK_SIZE = 1000\n",
    "\n",
    "# left_signal_cut = get_split_arr(arr=data, chunk_size=CHUNK_SIZE, col_to_split=0)\n",
    "mono_sound_split = split_arr(arr=mono_sound_to_cut, chunk_size=CHUNK_SIZE)\n",
    "mono_sound_split\n",
    "# print(len(mono_signal_cut))\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rB-5QutLJg27"
   },
   "source": [
    "#### 1.2. (3 points)\n",
    "\n",
    "Write a function that translates your `matrix` back into an audio signal. In other words, the function unwraps data from a matrix of size `(number of objects, 1000)` into a vector of length `(number of objects * 1000)`.\n",
    "\n",
    "Run the function and check that everything works correctly by playing the “restored” signal in your notebook - this signal should be exactly the same as the original one (because, in fact, it is)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Cu7WGVPYB47z",
    "outputId": "f94e305d-01ec-4db3-b3f9-bb999e745ebd"
   },
   "source": [
    "CHUNK_SIZE = 1000\n",
    "\n",
    "\n",
    "def reshape_into_original(arr: np.array, chunk_size: int = 1000, original_size: int = None) -> np.array:\n",
    "    original_size = original_size or len(arr)\n",
    "    arr = arr[:original_size]\n",
    "    arr = arr.reshape((len(arr) * chunk_size, ))\n",
    "\n",
    "    return arr\n",
    "\n",
    "\n",
    "def test_mono_signal_cut(arr1: np.array, arr2: np.array) -> None:\n",
    "    assert np.array_equal(arr1, arr2)\n",
    "\n",
    "\n",
    "mono_sound_reshaped_to_orig_after_split = reshape_into_original(mono_sound_split, CHUNK_SIZE)\n",
    "print('Arrays are equal:', np.array_equal(mono_sound_reshaped_to_orig_after_split, mono_sound_to_cut))\n",
    "\n",
    "Audio(mono_sound_reshaped_to_orig_after_split, rate=samplerate)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1sfw3ibiB8ua"
   },
   "source": [
    "### 2\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iHf0fecRj56w"
   },
   "source": [
    "#### 2.1. (3 points)\n",
    "\n",
    "Perform a PCA transformation of our matrix and get the data compressed into a lower dimensional space.\n",
    "\n",
    "_Hint. At this stage, we have our \"dataset\" with 1000 \"features\" and we want to reduce the number of \"features\" using the PCA method. You are free to choose the number of components, but initially, it is advisable not to choose too small a number. This way, if the result is poor, it will be easier to determine whether the number of components was insufficient or if there was an error somewhere else :)_\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hjk0u2MGLgvU"
   },
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "N_COMPONENTS = {\n",
    "    \"best\": 400,\n",
    "    \"nice\": 300,\n",
    "    \"good\": 200,\n",
    "    \"bad\": 100,\n",
    "    \"very_bad\": 50,\n",
    "}\n",
    "pca = PCA(n_components=N_COMPONENTS[\"good\"])\n",
    "\n",
    "\n",
    "mono_sound_compressed_w_pca = pca.fit_transform(mono_sound_split)\n",
    "print(\"Compressed matrix size =\", mono_sound_compressed_w_pca.shape, ' vs ', mono_sound_split.shape, 'as the initial one')\n",
    "\n",
    "# check if we can decompress\n",
    "mono_sound_decompressed_from_pca = pca.inverse_transform(mono_sound_compressed_w_pca)\n",
    "mono_sound_decompressed_from_pca = reshape_into_original(mono_sound_decompressed_from_pca)\n",
    "\n",
    "Audio(mono_sound_decompressed_from_pca, rate=samplerate)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nIdKtiIOLhWH"
   },
   "source": [
    "#### 2.2. (4 points)\n",
    "\n",
    "Visualize our \"objects\" in a clear form on a plane. Draw conclusions from their appearance.\n",
    "\n",
    "\n",
    "После проекции аудиосигнала на двумерное пространство с помощью PCA наблюдается плотная центральная область, окружённая разреженными выбросами. Это свидетельствует о том, что большая часть аудиосегментов имеет схожие характеристики - менее амплитудный звук, тогда как некоторые участки (более амплитудные музыкальные события) существенно отклоняются от общего фона. Структура облака точек относительно симметрична, что говорит об отсутствии ярко выраженного тренда или направленного изменения структуры сигнала во времени.\n",
    "\n",
    "_Hint. To do this, you need to apply PCA in some special way, which we also discussed in the seminar._"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cEzjTUfbLjAX"
   },
   "source": [
    "N_COMPONENTS_2D = 2\n",
    "pca_2d = PCA(n_components=N_COMPONENTS_2D)\n",
    "\n",
    "\n",
    "mono_sound_compressed_w_pca_2d = pca_2d.fit_transform(mono_sound_split)\n",
    "print(mono_sound_split.shape, ' vs ', mono_sound_compressed_w_pca_2d.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# ix = np.arange(len(mono_sound_compressed_w_pca_2d))\n",
    "# plt.scatter(mono_sound_compressed_w_pca_2d[:, 0], mono_sound_compressed_w_pca_2d[:, 1], c=ix, cmap='jet')\n",
    "\n",
    "\n",
    "plt.scatter(mono_sound_compressed_w_pca_2d[:, 0], mono_sound_compressed_w_pca_2d[:, 1], color=\"red\")\n",
    "plt.title(\"PCA sound projection to 2d plane\")\n",
    "plt.xlabel(\"first component\")\n",
    "plt.ylabel(\"second component\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# plt.scatter(mono_sound_split[:, 0], mono_sound_split[:, 1], color=\"blue\")\n",
    "# plt.legend([\"mono_sound_compressed_w_pca_2d\", \"mono_sound_split - two first columns\"])\n",
    "# plt.show()\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pandas import DataFrame\n",
    "a = DataFrame(mono_sound_compressed_w_pca_2d)\n",
    "a.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lv-Ts0W7lZUR"
   },
   "source": [
    "#### 2.3. (4 points)\n",
    "\n",
    "Create a scatter plot of the dataset in space using color. Draw conclusions from this graph. What is depicted overall?\n",
    "\n",
    "\n",
    "После проекции аудиосигнала на двумерное пространство с помощью PCA и цвета наблюдается большое количество точек в середине (цветом помечено именно количество точек). Это свидетельствует о том, что большая часть аудиосегментов имеет схожие характеристики - менее амплитудный звук, тогда как некоторые участки (более амплитудные музыкальные события) существенно отклоняются от общего фона. Структура облака точек относительно симметрична, что говорит об отсутствии ярко выраженного тренда или направленного изменения структуры сигнала во времени.\n",
    "\n",
    "\n",
    "\n",
    "_Hint. That's what we did in the seminar too. This is another special application of PCA._"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uzolLR40CjF1"
   },
   "source": [
    "pca_3d_or_2d = PCA(n_components=2)\n",
    "mono_sound_compressed_w_pca_3d_or_2d = pca_3d_or_2d.fit_transform(mono_sound_split)\n",
    "\n",
    "ix = np.arange(mono_sound_compressed_w_pca_3d_or_2d.shape[0])\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# ix = np.arange(len(mono_sound_compressed_w_pca_2d))\n",
    "# plt.scatter(mono_sound_compressed_w_pca_2d[:, 0], mono_sound_compressed_w_pca_2d[:, 1], c=ix, cmap='jet')\n",
    "\n",
    "\n",
    "plt.scatter(mono_sound_compressed_w_pca_3d_or_2d[:, 0], mono_sound_compressed_w_pca_3d_or_2d[:, 1], c=ix, cmap=\"PiYG\")\n",
    "plt.title(\"PCA sound projection to 2d plane\")\n",
    "plt.xlabel(\"first component\")\n",
    "plt.ylabel(\"second component\")\n",
    "plt.colorbar()\n",
    "plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# fig = plt.figure(figsize=(10, 7))\n",
    "# ax = fig.add_subplot(3, 1, (1, 4), projection='3d')\n",
    "#\n",
    "# plot1 = ax.scatter(\n",
    "#     mono_sound_compressed_w_pca_3d_or_2d[:, 0],\n",
    "#     mono_sound_compressed_w_pca_3d_or_2d[:, 1],\n",
    "#     mono_sound_compressed_w_pca_3d_or_2d[:, 2],\n",
    "#     c=ix,\n",
    "#     cmap='PiYG',\n",
    "# )\n",
    "#\n",
    "# ax.set_title(\"3d\")\n",
    "# ax.set_xlabel(\"first component\")\n",
    "# ax.set_ylabel(\"second component\")\n",
    "# ax.set_zlabel(\"third component\")\n",
    "#\n",
    "# fig.colorbar(plot1)\n",
    "# plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IKJYxUGgCkXq"
   },
   "source": [
    "### 3\n",
    "\n",
    "We need to deal with the actual \"compression\" of the sound and verify the correctness of our actions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z6lEkwKXNJGi"
   },
   "source": [
    "#### 3.1. (4 points)\n",
    "\n",
    "Perform inverse PCA transformation of the compressed data and get a “matrix” with the compressed sound. What will be the size of the resulting matrix?\n",
    "\n",
    "Так я же вроде сделал это в 2.1. Ну ладно - повторим\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "59G3sAXTNJQa"
   },
   "source": [
    "mono_sound_compressed_w_pca = pca.fit_transform(mono_sound_split)\n",
    "print(\"Compressed matrix size =\", mono_sound_compressed_w_pca.shape, ' vs ', mono_sound_split.shape, 'as the initial one')\n",
    "\n",
    "# check if we can decompress\n",
    "mono_sound_decompressed_from_pca = pca.inverse_transform(mono_sound_compressed_w_pca)\n",
    "mono_sound_decompressed_from_pca = reshape_into_original(mono_sound_decompressed_from_pca)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmLnumv4NJfQ"
   },
   "source": [
    "#### 3.2. (4 points)\n",
    "\n",
    "Convert the “matrix” obtained in the previous step into a playable signal (our “compressed” mono sound). Play the result `(Audio(YOUR_RESULT, rate = samplerate)`.\n",
    "\n",
    "Does the resulting sound resemble the original?\n",
    "\n",
    "\n",
    "Всё похоже - потому что взял хорошее качество, но плохую степень сжатия (1000 -> 200 фичей).\n",
    "Но если кол-во фичей уменьшим до 30-ти, то качество будет очень плохое, но похожесть на оригинал всё равно будет заметна (нижи 30 - становится уже прям почти не похоже)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7x_VAiJQCnNF"
   },
   "source": [
    "N_COMPONENTS = {\n",
    "    \"best\": 400,\n",
    "    \"nice\": 300,\n",
    "    \"good\": 200,\n",
    "    \"bad\": 100,\n",
    "    \"very_bad\": 50,\n",
    "    \"awful\": 30,\n",
    "}\n",
    "pca = PCA(n_components=N_COMPONENTS[\"awful\"])\n",
    "\n",
    "mono_sound_compressed_w_pca = pca.fit_transform(mono_sound_split)\n",
    "print(\"Compressed matrix size =\", mono_sound_compressed_w_pca.shape, ' vs ', mono_sound_split.shape, 'as the initial one')\n",
    "\n",
    "# check if we can decompress\n",
    "mono_sound_decompressed_from_pca = pca.inverse_transform(mono_sound_compressed_w_pca)\n",
    "mono_sound_decompressed_from_pca = reshape_into_original(mono_sound_decompressed_from_pca)\n",
    "\n",
    "\n",
    "Audio(mono_sound_decompressed_from_pca, rate=samplerate)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Su-TpE2jOMZm"
   },
   "source": [
    "#### 3.3. (8 points)\n",
    "\n",
    "Conduct a study of the dependence of sound quality on the number of components.\n",
    "\n",
    "Determine by ear the minimum number of components at which the sound is almost indistinguishable from the original.\n",
    "\n",
    "Add two variants of the soundtrack to the cells: the original and the one you have chosen. Specify the number of components you have chosen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1awFP0lWaFJ"
   },
   "source": [
    "_Hint. Try filtering the signal with the `gaussian_filter1d` function from `scipy.ndimage`. This will help remove the unpleasant shot noise when the compression is severe. You'll see what it's all about when you try it in practice._\n",
    "\n",
    "_Sample code for filtering: `Audio(gaussian_filter1d(mono_sound_compressed, 2), rate = samplerate)`_\n",
    "\n",
    "\n",
    "С gaussian_filter1d получается непохоже на оригинал - дажи при n_components=170. Хотя с другой стороны, на оригинал не похоже и с n_components=400 - звук будто чуть мутноватый, приглушённый.\n",
    "Чисто на слух, после n_components=130 качество почти не меняется => можно сказать, что 130 - минимальное число компонент для того, чтобы звук был без явных дефектов\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hYxikqAjO1rP"
   },
   "source": [
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "\n",
    "N_COMPONENTS = {\n",
    "    \"best\": 400,\n",
    "    \"nice\": 300,\n",
    "    \"good\": 200,\n",
    "    \"bad\": 100,\n",
    "    \"very_bad\": 50,\n",
    "    \"awful\": 30,\n",
    "}\n",
    "\n",
    "def get_compressed_mono_sound(n_components: int, is_gaussian_filter1d_used: bool = True) -> np.array:\n",
    "    ipca = PCA(n_components=n_components)\n",
    "    mono_sound_compressed_w_pca1 = ipca.fit_transform(mono_sound_split)\n",
    "    print(\"Compressed matrix size =\", mono_sound_compressed_w_pca1.shape)\n",
    "    mono_sound_decompressed_from_pca1 = ipca.inverse_transform(mono_sound_compressed_w_pca1)\n",
    "    mono_sound_decompressed_from_pca1 = reshape_into_original(mono_sound_decompressed_from_pca1)\n",
    "\n",
    "    if is_gaussian_filter1d_used:\n",
    "        return Audio(gaussian_filter1d(mono_sound_decompressed_from_pca1, 2), rate=samplerate)\n",
    "    return Audio(mono_sound_decompressed_from_pca1, rate=samplerate)\n",
    "\n",
    "\n",
    "print(\"Original\")\n",
    "display(Audio(mono_sound, rate=samplerate))\n",
    "# print(\"Best fake\")\n",
    "# display(get_compressed_mono_sound(N_COMPONENTS[\"best\"], is_gaussian_filter1d_used=False))\n",
    "\n",
    "for i in range(N_COMPONENTS[\"bad\"], N_COMPONENTS[\"good\"], 20):\n",
    "    display(get_compressed_mono_sound(i))\n",
    "    # display(get_compressed_mono_sound(i, is_gaussian_filter1d_used=False))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JG6sPku9Uslp"
   },
   "source": [
    "#### 3.4. (6 points)\n",
    "Argumentatively answer the following questions:\n",
    "- Is the number of components you have chosen too many or too few? How can you determine this?\n",
    "- To what extent can the sound be compressed in this way? What memory optimization did you achieve in the process?\n",
    "- If we are given a different soundtrack, we would need to do all the same things to compress the sound. How do we automatically select the number of components and is it possible?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qcEriqNmuM1E"
   },
   "source": [
    "1. 130 компонент - это 130 полей в матрице. Это много или мало? По мне так просто дофига! 1, 2, ну в крайнем случае 3 компонента - вот хорошее число.\n",
    "\n",
    "2. Сократили кол-во столбцов в матрице примерно в 8 раз, что теоретически может уменьшить размер занимаемой ими памяти в 8 раз (практически же это не совсем ясно - wav может иметь свой алгоритм сжатия, жёсткий диск/ssd тоже может хранить данные по-разному, поэтому эта степень сжатия примерная).\n",
    "\n",
    "3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6VSR-JNux9i"
   },
   "source": [
    "### 4"
   ]
  },
  {
   "metadata": {
    "id": "D0nMtm7lSP73"
   },
   "cell_type": "markdown",
   "source": [
    "#### Extra Research. (15 points).\n",
    "\n",
    "  - Wrap the resulting audio compression code in one or more functions.\n",
    "\n",
    "\n",
    "см код ниже\n",
    "\n",
    "\n",
    "  - Investigate how the compression ratio - the ratio of the size of the parts into which the signal was divided in task 1.1 to the size of the space into which you compressed the data using PCA - affects the sound, according to your subjective feelings. Starting from what compression level is the loss of audio track quality noticeable? (Both with and without `gaussian_filter1d` filtering).\n",
    "\n",
    "\n",
    "Коэффициент сжатия — это отношение изначальной размерности (например, 1000) к числу компонент после PCA (например, 1000 / 130 ≈ 7.7x сжатие). Будем считать 8 раз\n",
    "При сжатии выше чем 8 без фильтрации появляются шумы, искажения тембра, неприятные высокочастотные артефакты.\n",
    "С фильтрацией gaussian_filter1d звук становится мягче (\"должен становиться\" - я бы не сказал, звук становится будто хуже), но проблемы аналогичные.\n",
    "Субъективно: до 8x сжатия звук близок к оригиналу, после 8x — различия становятся заметны.\n",
    "\n",
    "\n",
    "  - What does the compression ratio mean for PCA? For a large audio recording (3 min, for example), would we want to break it into more, less, or the same number of segments as the proposed audio recording? Why?\n",
    "\n",
    "\n",
    "Для PCA коэффициент сжатия означает, насколько сильно уменьшается размерность входных данных (т.е. объём информации, необходимый для хранения и восстановления).\n",
    "\n",
    "Если мы берём длинный трек (например, 3 минуты), нам стоит делить его на такое же или большее количество сегментов (то есть сегменты меньшей длины), потому что:\n",
    "- аудиосигнал будет разнообразнее;\n",
    "- разные части трека будут содержать разные частоты и динамику;\n",
    "- лучше применять PCA отдельно к более коротким однородным отрезкам.\n",
    "Меньшее число крупных сегментов ухудшит компрессию, так как статистика PCA \"размоется\" и станет менее точной.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "  - Is there any way to automatically select the compression ratio? What is it responsible for in our task? How does the compression ratio affect the sound? Why does it affect the sound in this way?\n",
    "\n",
    "\n",
    "Да, можно использовать:\n",
    "- PCA(n_components=0.95): сохранит столько компонент, сколько нужно для покрытия 95% дисперсии;\n",
    "- смотреть на график накопленной дисперсии ( cum_var = np.cumsum(pca.explained_variance_ratio_) ).\n",
    "Коэффициент сжатия влияет на то, сколько информации мы сохраняем и сколько выбрасываем (в виде наименее важных компонент).\n",
    "Он влияет на звук напрямую: меньше компонент -> меньше деталей, меньше тембровой глубины -> искажения и потери нюансов.\n",
    "Это происходит потому, что PCA оставляет только наиболее \"энергетически значимые\" оси — а значит, мелкие детали, шумы, обертона — теряются при сильной компрессии."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1.\n",
    "def split_arr(arr: np.array, chunk_size: int = 1000, col_to_split: int = 0, n_components: int = 100) -> np.array:\n",
    "    from sklearn.decomposition import PCA\n",
    "\n",
    "    if arr.ndim > 1:\n",
    "        arr = arr[:, col_to_split]  # 0 - left column, 1 - the right one\n",
    "\n",
    "    arr_len = len(arr)\n",
    "\n",
    "    size_extend = 0\n",
    "    if arr_len % chunk_size != 0:\n",
    "        zero_to_add = chunk_size - arr_len % chunk_size\n",
    "        arr = np.pad(\n",
    "            array=arr,\n",
    "            pad_width=(0, zero_to_add),\n",
    "            mode='constant',\n",
    "        )  # expand the array with zeros if it is not divisible by chunk_size\n",
    "        size_extend = 1\n",
    "\n",
    "    chunk_cnt = arr_len // chunk_size + size_extend\n",
    "    arr = arr.reshape((chunk_cnt, chunk_size))\n",
    "\n",
    "    ipca = PCA(n_components=n_components)\n",
    "    arr = ipca.fit_transform(arr)\n",
    "\n",
    "    return arr\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
